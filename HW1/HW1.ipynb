{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\qwe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "m = MorphAnalyzer()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "import RAKE\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('russian')\n",
    "rake = RAKE.Rake(stop)\n",
    "from summa import keywords\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    lemmas = []\n",
    "    for t in simple_word_tokenize(text):\n",
    "        lemmas.append(m.parse(t)[0].normal_form)\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    text = tokenizer.tokenize(text.lower())\n",
    "    return [m.parse(t)[0].normal_form for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['индивидуальный',\n",
       "  'различие',\n",
       "  'характеристика',\n",
       "  'признак',\n",
       "  'психология',\n",
       "  'причина',\n",
       "  'личность'],\n",
       " ['психологический',\n",
       "  'тип',\n",
       "  'типология',\n",
       "  'характеристика',\n",
       "  'различие',\n",
       "  'группа',\n",
       "  'характер'],\n",
       " ['черта',\n",
       "  'психологический',\n",
       "  'характеристика',\n",
       "  'отличие',\n",
       "  'концептуализация',\n",
       "  'свойство',\n",
       "  'классификация'],\n",
       " ['интеллект', 'исследование', 'тип', 'показатель', 'информация', 'память'],\n",
       " ['личность', 'темперамент', 'эмоциональность', 'поведение', 'характеристика']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./texts/meta.txt', 'r', encoding='utf-8') as f:\n",
    "    meta = [normalize(line) for line in f.read().split('\\n')]\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for file in os.listdir('./texts'):\n",
    "    if file.startswith('text'):\n",
    "        path = os.path.join('./texts/', file)\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = int(file[4])\n",
    "            data.append(tuple([f.read(), meta[nb-1]]))\n",
    "\n",
    "corpus = [d[0] for d in data]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for file in os.listdir('./texts'):\n",
    "    if file.startswith('text'):\n",
    "        path = os.path.join('./texts/', file)\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data.append(tuple([f.read(), meta[nb-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textRank(text):\n",
    "    from gensim.summarization import keywords as kw\n",
    "    kw(normalize_text(text), pos_filter=[], scores=True)\n",
    " \n",
    "    keywords.keywords(normalize_text(text), additional_stopwords=stop, scores=True)\n",
    "    G = keywords.get_graph(text)\n",
    "    for edge in G.edges()[:7]:\n",
    "        print(edge, G.edge_weight(edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    " def TfIdf(text):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform([normalize_text(text)])\n",
    "    names = vectorizer.get_feature_names()\n",
    "    words = {}\n",
    "    for col in X.nonzero()[1]:\n",
    "        if names[col] not in stop:\n",
    "            words[names[col]] =  float(X[0, col])\n",
    "    top = sorted(words.items(), key = lambda x: x[1], reverse=True)\n",
    "    print(top[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('предмет', 'психологии') 1\n",
      "('психологии', 'предмет') 1\n",
      "('индивидуальных', 'психологии') 1\n",
      "('психологии', 'индивидуальных') 1\n",
      "('различий', 'индивидуальных') 1\n",
      "('индивидуальных', 'различий') 1\n",
      "('определяя', 'различий') 1\n",
      "============\n",
      "('гл', 'а') 1\n",
      "('а', 'гл') 1\n",
      "('в', 'а') 1\n",
      "('а', 'в') 1\n",
      "('психологические', 'а') 1\n",
      "('а', 'психологические') 1\n",
      "('типы', 'психологические') 1\n",
      "============\n",
      "('черты', 'как') 1\n",
      "('как', 'черты') 1\n",
      "('элементы', 'как') 1\n",
      "('как', 'элементы') 1\n",
      "('индивидуальности', 'элементы') 1\n",
      "('элементы', 'индивидуальности') 1\n",
      "('эволюция', 'индивидуальности') 1\n",
      "============\n",
      "('когнитивные', 'теории') 1\n",
      "('теории', 'когнитивные') 1\n",
      "('интеллекта', 'теории') 1\n",
      "('теории', 'интеллекта') 1\n",
      "('когнитивные', 'интеллекта') 1\n",
      "('интеллекта', 'когнитивные') 1\n",
      "('предполагают', 'интеллекта') 1\n",
      "============\n",
      "('глава', 'темперамент') 1\n",
      "('темперамент', 'глава') 1\n",
      "('и', 'темперамент') 1\n",
      "('темперамент', 'и') 1\n",
      "('личность', 'и') 1\n",
      "('и', 'личность') 1\n",
      "('никакие', 'личность') 1\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "for d in corpus:\n",
    "    textRank(d)\n",
    "    print('============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('различие', 0.4314105813833819), ('индивидуальный', 0.3763368901429502), ('психологический', 0.3029053018223745), ('характеристика', 0.25701055912201476), ('человек', 0.20193686788158302)]\n",
      "==================\n",
      "[('человек', 0.3462882894815818), ('психологический', 0.19392144210968582), ('характеристика', 0.18006991053042254), ('свой', 0.15236684737189599), ('характер', 0.12466378421336946)]\n",
      "==================\n",
      "[('который', 0.25288048254909207), ('человек', 0.25288048254909207), ('черта', 0.24315431014335778), ('свойство', 0.20424962052042053), ('индивидуальный', 0.19452344811468622)]\n",
      "==================\n",
      "[('интеллект', 0.6813071598754156), ('интеллектуальный', 0.19216355791357875), ('теория', 0.18342885073568882), ('время', 0.16595943637990893), ('показатель', 0.11355119331256927)]\n",
      "==================\n",
      "[('темперамент', 0.5141598130114088), ('реакция', 0.21708969882703927), ('характеристика', 0.21708969882703927), ('свойство', 0.19423815158208776), ('особенность', 0.19423815158208776)]\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "for d in corpus:\n",
    "    TfIdf(d)\n",
    "    print('==================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('индивидуальный различие', 3.9), ('психологический характеристика', 3.888888888888889), ('группа человек', 3.414285714285714), ('группа ребёнок', 3.0892857142857144), ('группа', 1.7142857142857142)]\n",
      "[('душевный склад', 4.0), ('человек', 1.5833333333333333), ('понять', 1.3333333333333333), ('спрашивать', 1.3333333333333333), ('группа', 1.2857142857142858)]\n",
      "[('разный ситуация', 4.0), ('собственный опыт', 4.0), ('общий психология', 4.0), ('музыкальный одарённость', 4.0), ('во-вторых', 4.0)]\n",
      "[('долговременный память', 4.0), ('приобретение знание', 4.0), ('интеллектуальный сфера', 4.0), ('когнитивный теория', 3.833333333333333), ('балл интеллект', 3.8157894736842106)]\n",
      "[('разный возраст', 4.0), ('разный автор', 3.857142857142857), ('кроме это', 3.75), ('иначе говорить', 3.666666666666667), ('американский исследователь', 3.666666666666667)]\n"
     ]
    }
   ],
   "source": [
    "for d in data:\n",
    "    print(rake.run(normalize_text(d[0]), minFrequency=2, maxWords=2)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# a = ['1', '2', '3']\n",
    "#b = ['1', '2', '4']\n",
    "# f1_score(a,b, average='micro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
