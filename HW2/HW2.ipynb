{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "pmm = MorphAnalyzer()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "import numpy as np\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('russian')\n",
    "from nltk.parse import DependencyGraph\n",
    "from collections import Counter\n",
    "from nltk.collocations import *\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = tokenizer.tokenize(text.lower())\n",
    "    lemmas = [pmm.parse(t)[0].normal_form for t in text]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Парсим корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !C:\\Users\\qwe\\Desktop\\cosyco\\udpipe\\udpipe-1.2.0-bin\\bin-win64\\udpipe --input horizontal --output conllu \\\n",
    "# --tokenize --tag --parse \\\n",
    "# C:\\Users\\qwe\\Desktop\\cosyco\\udpipe\\russian-syntagrus-ud-2.4-190531.udpipe < testset2.txt > text.conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = []\n",
    "with open('text.conllu', 'r', encoding='utf-8') as f:\n",
    "    parsed_sents = f.read().split('\\n\\n')\n",
    "    for sent in parsed_sents:\n",
    "        tree = [line for line in sent.split('\\n') if line and line[0] != '#']\n",
    "        trees.append('\\n'.join(tree))\n",
    "        \n",
    "\n",
    "print(trees[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Строим частотный словарь глаголов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_freq = Counter()\n",
    "for one_tree in trees:\n",
    "    try:\n",
    "        g = DependencyGraph(one_tree, top_relation_label='root')\n",
    "        for n in g.nodes:\n",
    "            if g.nodes[n]['ctag'] == 'VERB':\n",
    "                verb_freq[g.nodes[n]['lemma']] += 1\n",
    "    except:\n",
    "        pass\n",
    "verb_freq_50 = [item[0] for item in verb_freq.most_common() if item[1] >= 50]\n",
    "print(verb_freq_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Собираем все биграммы (глагол + прямое дополнение)\n",
    "\n",
    "-> биграммы в виде лемм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams = Counter()\n",
    "bigrams = []\n",
    "for one_tree in trees:\n",
    "    try:\n",
    "        g = DependencyGraph(one_tree, top_relation_label='root')\n",
    "        for item in g.triples():\n",
    "            if item[1] == 'obj' and item[2][1] == 'NOUN':\n",
    "                lemma = normalize_text(item[0][0])\n",
    "                if lemma in verb_freq_50:\n",
    "                    coll = tuple([normalize_text(item[0][0]), \n",
    "                                  normalize_text(item[2][0])])\n",
    "                    bigrams.append(coll)\n",
    "                    # bigrams[tuple([item[0][0], item[2][0]])] += 1\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оцениваем по метрикам log-likelihood, dice, PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_documents(bigrams)\n",
    "finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in nltk.corpus.stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglike_scores = {i[0]:i[1] for i in finder.score_ngrams(bigram_measures.likelihood_ratio)}\n",
    "pmi_scores = {i[0]:i[1] for i in finder.score_ngrams(bigram_measures.pmi)}\n",
    "dice_scores = {i[0]:i[1] for i in finder.score_ngrams(bigram_measures.dice)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_100 = finder.nbest(bigram_measures.pmi, 100)\n",
    "loglike_100 = finder.nbest(bigram_measures.likelihood_ratio, 100)\n",
    "dice_100 =  finder.nbest(bigram_measures.dice, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим пересечение трех метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_metrics = set(pmi_100) & set(loglike_100) & set(dice_100)\n",
    "three_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словарь глагольной сочетаемости\n",
    "\n",
    "* извлекае все словосочетания (из последней колонки) в том порядке, в котором они даны\n",
    "* лемматизируем\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verb_coll.txt', 'r', encoding='utf-8') as verb_coll:\n",
    "    verb_colls = verb_coll.read().split('\\n')\n",
    "\n",
    "verb_colls = [t.split('\\t')[-1] for t in verb_colls]\n",
    "verb_colls = [tuple(normalize_text(t).split()) for t in verb_colls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Находим Золотой стандарт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gold = set(verb_colls) & set(pmi_100) & set(loglike_100) & set(dice_100)\n",
    "Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Что осталось за пределами ЗС?\n",
    "three_metrics - Gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К ЗС можно было бы добавить следующие коллокации:\n",
    "\n",
    "* Объявить голодовку\n",
    "* заявить отвод\n",
    "* взыскать неустойку\n",
    "\n",
    "Критерием выделения коллокаций можно считать их фразеологичность и ограниченную сочетаемость составляющих коллокацию слов. Т.е чтобы проверить, является ли словосочетание коллокацией, нужно попробовать заменить слова\n",
    "\n",
    "Попробуем: \n",
    "\n",
    "* *сказать/проговорить/пообещать/заявить/прокричать голодовку\n",
    "* *объявить/сказать/проговорить отвод\n",
    "* ?собрать/взять/забрать неустойку (сказать что-то типа потребовать неустойку, наверное, можно, но взыскать неустойку звучит привычнее)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gold |= set([('взыскать', 'неустойка'), ('заявить', 'отвод'), ('объявить', 'голодовка')])\n",
    "Gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Считаем ранговую корреляцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loglike = dict.fromkeys(Gold)\n",
    "for item in Gold:\n",
    "    data_loglike[item] = loglike_scores[item]\n",
    "data_loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pmi = dict.fromkeys(Gold)\n",
    "for item in Gold:\n",
    "    data_pmi[item] = pmi_scores[item]\n",
    "data_pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dice = dict.fromkeys(Gold)\n",
    "for item in Gold:\n",
    "    data_dice[item] = dice_scores[item]\n",
    "data_dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Если считать, что коллокации в золотом стандарте - эталон, и приписать им всем оценку, близкую к 1.0, то корреляции не будет\n",
    "* Поэтому для каждой коллокации я попробовала взять ее усредненную оценку для всех трех метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = [0.9] * 7\n",
    "stats_m = [\n",
    "    list(data_loglike.values()),\n",
    "    list(data_pmi.values()),\n",
    "    list(data_dice.values())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stats_m:\n",
    "    print(stats.spearmanr(data0, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*берем среднее между тремя метриками*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = dict.fromkeys(Gold)\n",
    "for colloc in data1:\n",
    "    data1[colloc] = np.mean([pmi_scores[colloc], loglike_scores[colloc], dice_scores[colloc]])\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stats_m:\n",
    "    print(stats.spearmanr(list(data1.values()), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сами отранжировать коллокации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = [6, 3, 2, 4, 7, 5, 1]\n",
    "for i in stats_m:\n",
    "    print(stats.spearmanr(list(data3), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наибольшее значение корреляции у pmi, у других метрик значение корреляции сильно хуже\n",
    "\n",
    "PMI принимает во внимание именно то, насколько часто слова встречаются вместе, при учете их вероятностей по-отдельности\n",
    "\n",
    "Возможно, коллокации - это редкие слова по-отдельности, которые встречаются зачастую вместе, поэтому по-отдельности они не так значимы, как их сочетание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем посчитать рандомную корреляцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data2 =  np.random.random_sample((7,))\n",
    "for i in stats_m:\n",
    "    print(stats.spearmanr(data2, i))\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(pmi_100[:30]) & Gold, set(pmi_100[:50]) & Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(loglike_100[:30]) & Gold, set(loglike_100[:50]) & Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dice_100[:30]) & Gold, set(dice_100[:50]) & Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglike_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ\n",
    "\n",
    "* Оценка корреляции показала, что ближе всего к ЗС оказалась метрика loglikelihood\n",
    "* Меньше всего корреляция для PMI, на втором месте расположилась dice\n",
    "* Если мы сами оценим, насколько высокую оценку дают метрики для коллокаций, вошедших в ЗС, то увидим, что точнее всего оказывается dice: в первых 30 коллокаций встретилось больше сочетаний,вошедших в ЗС, чем для остальных метрик\n",
    "* Кажется, что для pmi важна еще и частотность отдельного слова в коллокации, если посмотреть на выдачу, то можно заметить, будто распределение коллокаций как будто сгруппировано по отдельным словам - вершинам коллокаций\n",
    "* Loglikelihood скорее в данном случае выбрал самые частотные сочетания слов, самые частотные биграммы. Вопрос: частотное словосочетание == коллокация?\n",
    "* Dice учитывает совместные сочетания слов, и чем частотнее слова встречаются вместе, чем меньше частотность отдельных слов, тем лучше. Однако ошибочны просто редкие сочетания, когда коллокация встретилась дишь один раз, и слова в ней встретились только в этой коллокации, оказываются в топе, что приводит к ошибочному выделению коллокации (('рассказать', 'замгендиректор'), ('являться', 'долг'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
